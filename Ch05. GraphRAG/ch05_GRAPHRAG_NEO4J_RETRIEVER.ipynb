{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8486,
     "status": "ok",
     "timestamp": 1740969850365,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "6ClqdrQx6f1G",
    "outputId": "978ff1d5-dfdc-4447-c870-64894a9619d1"
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain-neo4j langchain-openai langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4391,
     "status": "ok",
     "timestamp": 1740972199851,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "r8FfDMGk6cO8"
   },
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"/content/.env\")\n",
    "\n",
    "# 실제 인스턴스 정보를 입력합니다.\n",
    "NEO4J_URI = \"bolt://localhost\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"password\"\n",
    "NEO4J_DATABASE = \"neo4j\"\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Neo4j 그래프 객체 생성\n",
    "graph = Neo4jVector.from_existing_graph(\n",
    "    embedding=embedding,\n",
    "    node_label=\"__Entity__\",\n",
    "    text_node_properties=[\"description\"],\n",
    "    embedding_node_property=\"embedding\",\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")\n",
    "\n",
    "# Neo4jGraph 객체 추가 생성 (Cypher 쿼리 실행용)\n",
    "neo4j_graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740972987994,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "2e-7jR3LI2jO"
   },
   "outputs": [],
   "source": [
    "def fetch_entity_context(entity_name):\n",
    "    context = {\"name\": entity_name}\n",
    "    try:\n",
    "        # 텍스트 청크 가져오기\n",
    "        chunk_query = \"\"\"\n",
    "        MATCH (e:__Entity__ {name: $entity_name})<-[:HAS_ENTITY]-(c:__Chunk__)\n",
    "        RETURN c.text AS text\n",
    "        \"\"\"\n",
    "        chunk_result = neo4j_graph.query(chunk_query, {\"entity_name\": entity_name})\n",
    "        context[\"text_chunks\"] = [r[\"text\"] for r in chunk_result] if chunk_result else [\"No text chunk available\"]\n",
    "\n",
    "        # 커뮤니티 보고서 가져오기\n",
    "        community_query = \"\"\"\n",
    "        MATCH (e:__Entity__ {name: $entity_name})-[:IN_COMMUNITY]->(com:__Community__)\n",
    "        RETURN com.full_content AS report\n",
    "        \"\"\"\n",
    "        community_result = neo4j_graph.query(community_query, {\"entity_name\": entity_name})\n",
    "        context[\"community_reports\"] = [r[\"report\"] for r in community_result] if community_result else [\"No community report available\"]\n",
    "\n",
    "        # 관련 엔티티 가져오기\n",
    "        related_query = \"\"\"\n",
    "        MATCH (e:__Entity__ {name: $entity_name})-[:RELATED]->(related:__Entity__)\n",
    "        RETURN related.name AS name, related.description AS description\n",
    "        \"\"\"\n",
    "        related_result = neo4j_graph.query(related_query, {\"entity_name\": entity_name})\n",
    "        context[\"related_entities\"] = (\n",
    "            [{\"name\": r[\"name\"], \"description\": r[\"description\"]} for r in related_result]\n",
    "            if related_result else []\n",
    "        )\n",
    "    except Exception as e:\n",
    "        context[\"error\"] = f\"Error fetching context: {str(e)}\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740972989779,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "PbL2c3MgDxyU"
   },
   "outputs": [],
   "source": [
    "def create_structured_context(all_contexts, query):\n",
    "    context_str = \"## 질문과 관련된 엔티티 정보\\n\\n\"\n",
    "    context_str += \"아래는 질문에 답변하는 데 유용한 엔티티들의 구조화된 정보입니다:\\n\\n\"\n",
    "\n",
    "    for i, ctx in enumerate(all_contexts, 1):\n",
    "        context_str += f\"### 엔티티 {i}: {ctx['name']}\\n\"\n",
    "        context_str += f\"- **설명**: {ctx['description']}\\n\"\n",
    "        context_str += \"- **텍스트 청크**:\\n\"\n",
    "        for chunk in ctx['text_chunks']:\n",
    "            context_str += f\"  - {chunk}\\n\"\n",
    "        context_str += \"- **커뮤니티 보고서**:\\n\"\n",
    "        for report in ctx['community_reports']:\n",
    "            context_str += f\"  - {report}\\n\"\n",
    "        if ctx['related_entities']:\n",
    "            context_str += \"- **관련 엔티티**:\\n\"\n",
    "            for rel in ctx['related_entities']:\n",
    "                context_str += f\"  - {rel['name']}: {rel['description']}\\n\"\n",
    "        else:\n",
    "            context_str += \"- **관련 엔티티**: 없음\\n\"\n",
    "        context_str += \"\\n\"\n",
    "    return context_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqlzWcTdG90M"
   },
   "outputs": [],
   "source": [
    "# LLM 설정 (예: GPT-4o)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# 리트리버 설정\n",
    "retriever = graph.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20584,
     "status": "ok",
     "timestamp": 1740973068336,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "qDhYdeHlHPFx",
    "outputId": "b193a81f-36ba-466c-9495-97f1e32aebcd"
   },
   "outputs": [],
   "source": [
    "# 질문 설정\n",
    "query = \"마일당 순이익(NET INCOME PER MILE)을 어떻게 분석해야 하나요?\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "\n",
    "# 모든 엔티티의 컨텍스트 수집\n",
    "all_contexts = []\n",
    "for result in results:\n",
    "    entity_name = result.metadata.get(\"name\", \"Unknown\")\n",
    "    description = result.page_content\n",
    "    context = fetch_entity_context(entity_name)\n",
    "    context[\"name\"] = entity_name\n",
    "    context[\"description\"] = description\n",
    "    all_contexts.append(context)\n",
    "\n",
    "context_str = create_structured_context(all_contexts, query)\n",
    "prompt = f\"아래 맥락에 기반해서, 주어진 질문에 한국어로 답하세요\\n\\n**질문**: {query}\\n\\n**맥락**:\\n{context_str}\"\n",
    "response = llm.invoke(prompt)\n",
    "print(\"Final Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvLXTBwz8XqN"
   },
   "source": [
    "Global Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvOcdQM_Nc8d"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MoHYrMBlN1Pw"
   },
   "outputs": [],
   "source": [
    "MAP_SYSTEM_PROMPT = \"\"\"\n",
    "---역할---\n",
    "제공된 컨텍스트를 참고하여 사용자의 질문에 답하는 어시스턴트입니다.\n",
    "\n",
    "---목표---\n",
    "주어진 컨텍스트가 질문을 답하기에 적절하다면 질문에 대한 답을 한 뒤, 답변의 중요도 점수를 기입하여 JSON 형식으로 생성하세요.\n",
    "정보가 부족하면 \"모르겠습니다\"라고 답하세요.\n",
    "\n",
    "각 포인트는 다음을 포함해야 합니다:\n",
    "- 답변: 질문에 대한 답변\n",
    "- 중요도 점수: 0~100 사이의 정수.\n",
    "\n",
    "데이터 참조 예:\n",
    "\"예시 문장 [Data: Reports (2, 7, 64, 46, 34, +more)]\"\n",
    "(한 참조에 5개 이상의 id는 \"+more\"를 사용)\n",
    "\n",
    "출력 예:\n",
    "{{\"Answer\": \"답변 [Data: Reports (보고서 id들)]\", \"score\": 점수}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", MAP_SYSTEM_PROMPT),\n",
    "        (\"human\", \"question: {question}\\n\\n context: {context}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "map_chain = map_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1740925821934,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "-biNLT4lJgHT"
   },
   "outputs": [],
   "source": [
    "REDUCE_SYSTEM_PROMPT = \"\"\"\n",
    "---역할---\n",
    "맵 단계에서 처리된 여러 결과를 종합하여 사용자의 질문에 답하는 어시스턴트입니다.\n",
    "\n",
    "---목표---\n",
    "제공된 맵 단계 결과를 바탕으로, 질문에 대한 종합적인 답변을 마크다운 형식으로 작성하세요.\n",
    "중요도 점수를 고려하여 핵심적인 결과 위주로 반영하며, 불필요한 세부 사항은 제외하세요.\n",
    "핵심 포인트와 시사점을 포함하고, 정보가 부족한 경우 \"모르겠습니다\"라고 답하세요.\n",
    "\n",
    "---맵 단계 결과---\n",
    "{report_data}\n",
    "\n",
    "데이터 참조 형식은 아래를 따르세요:\n",
    "\"예시 문장 [Data: Reports (2, 7, 34, 46, 64, +more)]\"\n",
    "(참조 ID가 5개 이상일 경우 \"+more\" 사용)\n",
    "\n",
    "대상 응답 길이 및 형식: {response_type}\n",
    "\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", REDUCE_SYSTEM_PROMPT),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reduce_chain = reduce_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1656,
     "status": "ok",
     "timestamp": 1740925830975,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "pLjbiypseBl_"
   },
   "outputs": [],
   "source": [
    "response_type: str = \"multiple paragraphs\"\n",
    "\n",
    "\n",
    "def global_retriever(query: str, level: int, response_type: str = response_type) -> str:\n",
    "    community_data = graph.query(\n",
    "        \"\"\"\n",
    "    MATCH (c:__Community__)\n",
    "    WHERE c.level = $level\n",
    "    RETURN c.full_content AS output\n",
    "    \"\"\",\n",
    "        params={\"level\": level},\n",
    "    )\n",
    "    intermediate_results = []\n",
    "    for community in tqdm(community_data, desc=\"Processing communities\"):\n",
    "        intermediate_response = map_chain.invoke(\n",
    "            {\"question\": query, \"context\": community[\"output\"]}\n",
    "        )\n",
    "        intermediate_results.append(intermediate_response)\n",
    "    final_response = reduce_chain.invoke(\n",
    "        {\n",
    "            \"report_data\": intermediate_results,\n",
    "            \"question\": query,\n",
    "            \"response_type\": response_type,\n",
    "        }\n",
    "    )\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180278,
     "status": "ok",
     "timestamp": 1740926387772,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "wM_pbg5veDYB",
    "outputId": "9f2fe5e7-16b6-4ee1-eba8-ae7ba797e503"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "print(global_retriever(\"이 책의 주제가 뭐야?\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XN7nOc6xRAoj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPnU11l2MEeYfT+cDaTA2hl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
