{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8486,
     "status": "ok",
     "timestamp": 1740969850365,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "6ClqdrQx6f1G",
    "outputId": "978ff1d5-dfdc-4447-c870-64894a9619d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
      "Collecting neo4j\n",
      "  Downloading neo4j-5.28.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.40)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from neo4j) (2025.1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.61.1)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading neo4j-5.28.1-py3-none-any.whl (312 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.3.7-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, neo4j, mypy-extensions, marshmallow, httpx-sse, typing-inspect, tiktoken, pydantic-settings, dataclasses-json, langchain-openai, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-openai-0.3.7 langchain_community-0.3.18 marshmallow-3.26.1 mypy-extensions-1.0.0 neo4j-5.28.1 pydantic-settings-2.8.1 python-dotenv-1.0.1 tiktoken-0.9.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain neo4j langchain-openai langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4391,
     "status": "ok",
     "timestamp": 1740972199851,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "r8FfDMGk6cO8"
   },
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"/content/.env\")\n",
    "\n",
    "# 실제 인스턴스 정보를 입력합니다.\n",
    "NEO4J_URI = \"bolt://localhost\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"password\"\n",
    "NEO4J_DATABASE = \"neo4j\"\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Neo4j 그래프 객체 생성\n",
    "graph = Neo4jVector.from_existing_graph(\n",
    "    embedding=embedding,\n",
    "    node_label=\"__Entity__\",\n",
    "    text_node_properties=[\"description\"],\n",
    "    embedding_node_property=\"embedding\",\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")\n",
    "\n",
    "# Neo4jGraph 객체 추가 생성 (Cypher 쿼리 실행용)\n",
    "neo4j_graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740972987994,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "2e-7jR3LI2jO"
   },
   "outputs": [],
   "source": [
    "def fetch_entity_context(entity_name):\n",
    "    context = {\"name\": entity_name}\n",
    "    try:\n",
    "        # 텍스트 청크 가져오기\n",
    "        chunk_query = \"\"\"\n",
    "        MATCH (e:__Entity__ {name: $entity_name})<-[:HAS_ENTITY]-(c:__Chunk__)\n",
    "        RETURN c.text AS text\n",
    "        \"\"\"\n",
    "        chunk_result = neo4j_graph.query(chunk_query, {\"entity_name\": entity_name})\n",
    "        context[\"text_chunks\"] = [r[\"text\"] for r in chunk_result] if chunk_result else [\"No text chunk available\"]\n",
    "\n",
    "        # 커뮤니티 보고서 가져오기\n",
    "        community_query = \"\"\"\n",
    "        MATCH (e:__Entity__ {name: $entity_name})-[:IN_COMMUNITY]->(com:__Community__)\n",
    "        RETURN com.full_content AS report\n",
    "        \"\"\"\n",
    "        community_result = neo4j_graph.query(community_query, {\"entity_name\": entity_name})\n",
    "        context[\"community_reports\"] = [r[\"report\"] for r in community_result] if community_result else [\"No community report available\"]\n",
    "\n",
    "        # 관련 엔티티 가져오기\n",
    "        related_query = \"\"\"\n",
    "        MATCH (e:__Entity__ {name: $entity_name})-[:RELATED]->(related:__Entity__)\n",
    "        RETURN related.name AS name, related.description AS description\n",
    "        \"\"\"\n",
    "        related_result = neo4j_graph.query(related_query, {\"entity_name\": entity_name})\n",
    "        context[\"related_entities\"] = (\n",
    "            [{\"name\": r[\"name\"], \"description\": r[\"description\"]} for r in related_result]\n",
    "            if related_result else []\n",
    "        )\n",
    "    except Exception as e:\n",
    "        context[\"error\"] = f\"Error fetching context: {str(e)}\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740972989779,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "PbL2c3MgDxyU"
   },
   "outputs": [],
   "source": [
    "def create_structured_context(all_contexts, query):\n",
    "    context_str = \"## 질문과 관련된 엔티티 정보\\n\\n\"\n",
    "    context_str += \"아래는 질문에 답변하는 데 유용한 엔티티들의 구조화된 정보입니다:\\n\\n\"\n",
    "\n",
    "    for i, ctx in enumerate(all_contexts, 1):\n",
    "        context_str += f\"### 엔티티 {i}: {ctx['name']}\\n\"\n",
    "        context_str += f\"- **설명**: {ctx['description']}\\n\"\n",
    "        context_str += \"- **텍스트 청크**:\\n\"\n",
    "        for chunk in ctx['text_chunks']:\n",
    "            context_str += f\"  - {chunk}\\n\"\n",
    "        context_str += \"- **커뮤니티 보고서**:\\n\"\n",
    "        for report in ctx['community_reports']:\n",
    "            context_str += f\"  - {report}\\n\"\n",
    "        if ctx['related_entities']:\n",
    "            context_str += \"- **관련 엔티티**:\\n\"\n",
    "            for rel in ctx['related_entities']:\n",
    "                context_str += f\"  - {rel['name']}: {rel['description']}\\n\"\n",
    "        else:\n",
    "            context_str += \"- **관련 엔티티**: 없음\\n\"\n",
    "        context_str += \"\\n\"\n",
    "    return context_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqlzWcTdG90M"
   },
   "outputs": [],
   "source": [
    "# LLM 설정 (예: GPT-4o)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# 리트리버 설정\n",
    "retriever = graph.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20584,
     "status": "ok",
     "timestamp": 1740973068336,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "qDhYdeHlHPFx",
    "outputId": "b193a81f-36ba-466c-9495-97f1e32aebcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response:\n",
      "마일당 순이익(NET INCOME PER MILE)을 분석할 때 다음의 주요 요소들을 고려해야 합니다:\n",
      "\n",
      "1. **순이익 계산**: 순이익은 총 수익에서 운영 비용(때로는 세금)을 뺀 다음, 다른 소득원을 추가하여 계산됩니다. 이는 철도의 수익성 및 재무 건전성을 평가하는 중요한 척도입니다.\n",
      "\n",
      "2. **운영 비용 분석**: 운영 비용은 총 수익의 약 65%를 차지하는 것이 일반적이며, 이는 철도의 재정 관리와 효율성을 평가하는 데 중요한 역할을 합니다. 운영 비용과 총 수익의 균형을 이해하면 철도의 재정 관리 관행 및 수익성 잠재력을 평가하는 데 유용합니다.\n",
      "\n",
      "3. **성장 추세 확인**: 보고서를 통해 순이익이 증가하고 있는지 아니면 감소하고 있는지를 파악해야 합니다. 이것은 철도의 운영 효율성을 평가하는 데 중요한 정보입니다.\n",
      "\n",
      "4. **비교 분석**: 같은 분야의 다른 철도와의 순이익 비교 분석을 통해 해당 철도의 상대적 위치와 경쟁력을 평가할 수 있습니다.\n",
      "\n",
      "5. **고정비 비중**: 순이익과 고정비(예: 채권 이자 및 세금) 간의 비율을 파악하여 철도의 재무 안정성을 평가할 수 있습니다. 일반적으로 산업 채권이 호의적으로 평가받기 위해서는 연간 순이익이 연간 채권 이자, 세금 및 저당 기금의 약 세 배가 되어야 합니다.\n",
      "\n",
      "6. **투자 및 유지보수**: 철도의 주요 설비, 노후된 자산들의 유지보수, 자본 집행 투자 등이 적절하게 이루어지고 있는지 확인하여 철도의 장기적 안정성을 평가하는 것이 중요합니다.\n",
      "\n",
      "이러한 요소를 분석하여 마일당 순이익이 철도의 효율성 및 재무 건전성을 어떻게 나타내는지 이해할 수 있습니다. 이를 통해 투자자들은 철도에 대한 투자 결정을 내리는 데 유용한 정보를 얻을 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 질문 설정\n",
    "query = \"마일당 순이익(NET INCOME PER MILE)을 어떻게 분석해야 하나요?\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "\n",
    "# 모든 엔티티의 컨텍스트 수집\n",
    "all_contexts = []\n",
    "for result in results:\n",
    "    entity_name = result.metadata.get(\"name\", \"Unknown\")\n",
    "    description = result.page_content\n",
    "    context = fetch_entity_context(entity_name)\n",
    "    context[\"name\"] = entity_name\n",
    "    context[\"description\"] = description\n",
    "    all_contexts.append(context)\n",
    "\n",
    "context_str = create_structured_context(all_contexts, query)\n",
    "prompt = f\"아래 맥락에 기반해서, 주어진 질문에 한국어로 답하세요\\n\\n**질문**: {query}\\n\\n**맥락**:\\n{context_str}\"\n",
    "response = llm.invoke(prompt)\n",
    "print(\"Final Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvLXTBwz8XqN"
   },
   "source": [
    "Global Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvOcdQM_Nc8d"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MoHYrMBlN1Pw"
   },
   "outputs": [],
   "source": [
    "MAP_SYSTEM_PROMPT = \"\"\"\n",
    "---역할---\n",
    "제공된 컨텍스트를 참고하여 사용자의 질문에 답하는 어시스턴트입니다.\n",
    "\n",
    "---목표---\n",
    "질문과 관련된 컨텍스트 정보를 요약한 주요 포인트 목록을 JSON 형식으로 생성하세요.\n",
    "정보가 부족하면 \"모르겠습니다\"라고 답하세요.\n",
    "\n",
    "각 포인트는 다음을 포함해야 합니다:\n",
    "- 설명: 포인트에 대한 상세 설명.\n",
    "- 중요도 점수: 0~100 사이의 정수.\n",
    "\n",
    "데이터 참조 예:\n",
    "\"예시 문장 [Data: Reports (2, 7, 64, 46, 34, +more)]\"\n",
    "(한 참조에 5개 이상의 id는 \"+more\"를 사용)\n",
    "\n",
    "출력 예:\n",
    "{{\n",
    "    \"points\": [\n",
    "        {{\"description\": \"포인트 1 설명 [Data: Reports (보고서 id들)]\", \"score\": 점수}},\n",
    "        {{\"description\": \"포인트 2 설명 [Data: Reports (보고서 id들)]\", \"score\": 점수}}\n",
    "    ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", MAP_SYSTEM_PROMPT),\n",
    "        (\"human\", \"question: {question}\\n\\n context: {context}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "map_chain = map_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1740925821934,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "-biNLT4lJgHT"
   },
   "outputs": [],
   "source": [
    "REDUCE_SYSTEM_PROMPT = \"\"\"\n",
    "---역할---\n",
    "여러 분석가의 보고서를 종합하여 사용자의 질문에 답하는 어시스턴트입니다.\n",
    "\n",
    "---목표---\n",
    "제공된 분석가 보고서를 바탕으로, 질문에 대한 종합적인 답변을 마크다운 형식으로 작성하세요.\n",
    "불필요한 정보를 제거하고, 핵심 포인트와 시사점을 포함하세요.\n",
    "정보가 부족하면 \"모르겠습니다\"라고 답하세요.\n",
    "\n",
    "---분석가 보고서---\n",
    "{report_data}\n",
    "\n",
    "데이터 참조는 다음 형식을 유지하세요:\n",
    "\"예시 문장 [Data: Reports (2, 7, 34, 46, 64, +more)]\"\n",
    "(한 참조에 5개 이상의 id는 \"+more\"를 사용)\n",
    "\n",
    "대상 응답 길이 및 형식: {response_type}\n",
    "\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", REDUCE_SYSTEM_PROMPT),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reduce_chain = reduce_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 1656,
     "status": "ok",
     "timestamp": 1740925830975,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "pLjbiypseBl_"
   },
   "outputs": [],
   "source": [
    "response_type: str = \"multiple paragraphs\"\n",
    "\n",
    "\n",
    "def global_retriever(query: str, level: int, response_type: str = response_type) -> str:\n",
    "    community_data = graph.query(\n",
    "        \"\"\"\n",
    "    MATCH (c:__Community__)\n",
    "    WHERE c.level = $level\n",
    "    RETURN c.full_content AS output\n",
    "    \"\"\",\n",
    "        params={\"level\": level},\n",
    "    )\n",
    "    intermediate_results = []\n",
    "    for community in tqdm(community_data, desc=\"Processing communities\"):\n",
    "        intermediate_response = map_chain.invoke(\n",
    "            {\"question\": query, \"context\": community[\"output\"]}\n",
    "        )\n",
    "        intermediate_results.append(intermediate_response)\n",
    "    final_response = reduce_chain.invoke(\n",
    "        {\n",
    "            \"report_data\": intermediate_results,\n",
    "            \"question\": query,\n",
    "            \"response_type\": response_type,\n",
    "        }\n",
    "    )\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180278,
     "status": "ok",
     "timestamp": 1740926387772,
     "user": {
      "displayName": "김재웅",
      "userId": "06729560528582252852"
     },
     "user_tz": -540
    },
    "id": "wM_pbg5veDYB",
    "outputId": "9f2fe5e7-16b6-4ee1-eba8-ae7ba797e503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-30-fa14bd32d2f6>\u001b[0m(22)\u001b[0;36mglobal_retriever\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     21 \u001b[0;31m    \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 22 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mcommunity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommunity_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Processing communities\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     23 \u001b[0;31m        intermediate_response = map_chain.invoke(\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing communities: 100%|██████████| 22/22 [02:46<00:00,  7.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-30-fa14bd32d2f6>\u001b[0m(28)\u001b[0;36mglobal_retriever\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     27 \u001b[0;31m    \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 28 \u001b[0;31m    final_response = reduce_chain.invoke(\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m        {\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "이 책은 금융 생태계 내에서 다양한 금융 자산 간의 상호작용과 경제 주기의 영향을 탐구하고 있습니다. 주로 채권, 주식, 경기침체에 집중하며, 투자와 관련된 다양한 전략과 시장 영향을 다룹니다. 경제적 사이클과 금리 변동이 채권 및 주식의 가치 평가에 미치는 영향을 비롯하여, 사업 상황과 경제적 조건이 중등급 및 저등급 채권과 주식의 성과에 미치는 영향을 설명합니다.\n",
      "\n",
      "금리가 경제 활동과 투자 결정에 중심적인 역할을 하며, 이러한 금리 변동의 영향력이 채권 시장, 특히 고급 채권과 선택된 지방채, 그리고 2급 철도 발행물에서 어떻게 나타나는지를 분석합니다. 또한, 투자자들이 금리와 신용 사이클에 대한 주의를 기울여야 함을 강조하고 있습니다. 채권, 특히 저등급 채권은 금리 변화에 민감하며, 이에 따라 투자자들은 금리 및 신용 사이클을 면밀히 모니터링해야 합니다.\n",
      "\n",
      "경제적 사이클 또한 투자 결정에 있어 중요하며, 유동 자본의 흐름과 경제 번영 및 침체 사이의 전환이 새 사업을 촉진하는 방식에 대해서도 논의합니다. 이러한 경제 주기가 금융 안정성에 미치는 영향을 통해 정책 입안자와 투자자들이 경제 변동에 대비할 수 있도록 도움을 제공합니다.\n",
      "\n",
      "[Data: Reports (53, 59, 70, 116, 124, 125, +more)]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "print(global_retriever(\"이 책의 주제가 뭐야?\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XN7nOc6xRAoj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPnU11l2MEeYfT+cDaTA2hl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
