{"cells":[{"cell_type":"code","execution_count":null,"id":"cJy1t37GsyL9","metadata":{"id":"cJy1t37GsyL9"},"outputs":[],"source":["!pip install langchain langchain_openai langchain_community pypdf faiss-cpu"]},{"cell_type":"code","execution_count":null,"id":"U3aOf1kttmdQ","metadata":{"id":"U3aOf1kttmdQ"},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","\n","# .env 파일에서 환경 변수 로드\n","load_dotenv(\"/content/.env\")\n","\n","# 환경 변수에서 API 키 가져오기\n","os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"]},{"cell_type":"code","execution_count":null,"id":"u9eVNXBIUTsb","metadata":{"id":"u9eVNXBIUTsb"},"outputs":[],"source":["from langchain_community.document_loaders import PyPDFLoader\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","\n","file_path = (\n","    \"/content/투자설명서.pdf\"\n",")\n","loader = PyPDFLoader(file_path)\n","\n","doc_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap = 100)\n","\n","docs = loader.load_and_split(doc_splitter)"]},{"cell_type":"code","execution_count":null,"id":"wtwTgjcwQp1o","metadata":{"id":"wtwTgjcwQp1o"},"outputs":[],"source":["from langchain_openai.embeddings import OpenAIEmbeddings\n","\n","# 데이터를 임베딩으로 변환\n","embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")"]},{"cell_type":"code","execution_count":null,"id":"p3PNlgs44qHB","metadata":{"id":"p3PNlgs44qHB"},"outputs":[],"source":["# FAISS 라이브러리 임포트\n","from langchain_community.vectorstores import FAISS\n","\n","# FAISS 벡터스토어 생성\n","faiss_store = FAISS.from_documents(docs, embedding)\n","# FAISS 벡터스토어 저장\n","persist_directory = \"/content/DB\"\n","faiss_store.save_local(persist_directory)"]},{"cell_type":"code","execution_count":null,"id":"urRxIxM3sUcS","metadata":{"id":"urRxIxM3sUcS"},"outputs":[],"source":["# 저장한 FAISS DB 불러오기\n","vectordb = FAISS.load_local(persist_directory, embeddings=embedding, allow_dangerous_deserialization=True)"]},{"cell_type":"code","execution_count":null,"id":"QO7i-mOHQ4vx","metadata":{"id":"QO7i-mOHQ4vx"},"outputs":[],"source":["from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain.docstore.document import Document\n","from typing import List, Dict, Any, Tuple\n","from langchain.chat_models import ChatOpenAI\n","from sentence_transformers import CrossEncoder\n","from langchain_core.retrievers import BaseRetriever\n","from langchain.chains import RetrievalQA"]},{"cell_type":"code","execution_count":null,"id":"NkIsOHAOQ7AY","metadata":{"id":"NkIsOHAOQ7AY"},"outputs":[],"source":["# ms-marco-MiniLM-L-12-v2 모델 다운로드\n","crossencoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')"]},{"cell_type":"code","execution_count":null,"id":"sLBgdtjK6UUX","metadata":{"id":"sLBgdtjK6UUX"},"outputs":[],"source":["class Retriever_with_cross_encoder(BaseRetriever):\n","    vectorstore: Any = Field(description=\"초기 검색을 위한 벡터 저장소\")\n","    crossencoder: Any = Field(description=\"재순위화를 위한 크로스 인코더 모델\")\n","    k: int = Field(default=5, description=\"초기에 검색할 문서 수\")\n","    rerank_top_k: int = Field(default=2, description=\"재순위화 후 최종적으로 반환할 문서 수\")\n","\n","    class Config:\n","        arbitrary_types_allowed = True\n","\n","    def get_relevant_documents(self, query: str) -> List[Document]:\n","        # 초기 검색\n","        initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n","\n","        # 인코더용 쌍 준비\n","        pairs = [[query, doc.page_content] for doc in initial_docs]\n","\n","        # 인코더 점수 획득\n","        scores = self.crossencoder.predict(pairs)\n","\n","        # 점수별 문서 정렬\n","        scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n","\n","        # 상위 재순위화 문서 반환\n","        return [doc for doc, _ in scored_docs[:self.rerank_top_k]]"]},{"cell_type":"code","execution_count":null,"id":"GQgtEgOLRtwJ","metadata":{"id":"GQgtEgOLRtwJ"},"outputs":[],"source":["# 크로스인코더 기반 리트리버 인스턴스 생성\n","cross_encoder_retriever = Retriever_with_cross_encoder(\n","    vectorstore=vectordb,\n","    crossencoder=crossencoder,\n","    k=4,  # 초기 밀집검색으로 반환할 문서 수를 설정\n","    rerank_top_k=2  # 리랭킹을 통해 최종적으로 반환할 문서 수를 설정\n",")\n","\n","# 답변용 LLM 인스턴스 생성\n","llm = ChatOpenAI(temperature=0.2, model_name=\"gpt-4o\")"]},{"cell_type":"code","execution_count":null,"id":"XRsXe5Q47eft","metadata":{"id":"XRsXe5Q47eft"},"outputs":[],"source":["# RetrievalQA 체인 인스턴스 생성\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm=llm,\n","    chain_type=\"stuff\",\n","    retriever=cross_encoder_retriever,\n","    return_source_documents=True\n",")"]},{"cell_type":"code","execution_count":null,"id":"GtjlHUxKIOm4","metadata":{"id":"GtjlHUxKIOm4"},"outputs":[],"source":["query = \"이 회사의 2022년 영업손실이 정확히 얼마야?\"\n","result = qa_chain({\"query\": query})\n","\n","print(f\"\\n질문: {query}\")\n","print(f\"답변: {result['result']}\")\n","print(\"\\n답변 근거 문서:\")\n","for i, doc in enumerate(result[\"source_documents\"]):\n","    print(f\"\\nDocument {i+1}:\")\n","    print(doc.page_content)  # Print each document"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":5}
