{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cJy1t37GsyL9",
   "metadata": {
    "id": "cJy1t37GsyL9"
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain_openai langchain_community pypdf faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# 먼저 구글 드라이브 마운트\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U3aOf1kttmdQ",
   "metadata": {
    "id": "U3aOf1kttmdQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"/content/.env\")\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u9eVNXBIUTsb",
   "metadata": {
    "id": "u9eVNXBIUTsb"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_path = (\n",
    "    \"/content/drive/MyDrive/langchain-tutorial/Ch04. Advanced Rag/Data/투자설명서.pdf\"\n",
    ")\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "doc_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap = 100)\n",
    "\n",
    "docs = loader.load_and_split(doc_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "th1jORGqyHWR",
   "metadata": {
    "id": "th1jORGqyHWR"
   },
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 데이터를 임베딩으로 변환\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p3PNlgs44qHB",
   "metadata": {
    "id": "p3PNlgs44qHB"
   },
   "outputs": [],
   "source": [
    "# FAISS 라이브러리 임포트\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS 벡터스토어 생성\n",
    "faiss_store = FAISS.from_documents(docs, embedding)\n",
    "# FAISS 벡터스토어 저장\n",
    "persist_directory = \"/content/DB\"\n",
    "faiss_store.save_local(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urRxIxM3sUcS",
   "metadata": {
    "id": "urRxIxM3sUcS"
   },
   "outputs": [],
   "source": [
    "# 저장한 FAISS DB 불러오기\n",
    "vectordb = FAISS.load_local(persist_directory, embeddings=embedding, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WZ8Fzu2VyoC6",
   "metadata": {
    "id": "WZ8Fzu2VyoC6"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain import PromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from langchain_openai import ChatOpenAI\n",
    "from textwrap import dedent\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5F4CIf3CO0An",
   "metadata": {
    "id": "5F4CIf3CO0An"
   },
   "outputs": [],
   "source": [
    "class RelevanceScore(BaseModel):\n",
    "    relevance_score: float = Field(description=\"문서가 쿼리와 얼마나 관련이 있는지를 나타내는 점수.\")\n",
    "\n",
    "def reranking_documents(query: str, docs: List[Document], top_n: int = 2) -> List[Document]:\n",
    "    parser = JsonOutputParser(pydantic_object=RelevanceScore)\n",
    "    human_message_prompt = PromptTemplate(\n",
    "        template = \"\"\"\n",
    "        1점부터 10점까지 점수를 매겨, 다음 문서가 질문이 얼마나 관련이 있는지 평가해주세요. 단순히 키워드가 일치하는 것이 아니라 쿼리의 구체적인 맥락과 의도를 고려하세요.\n",
    "        {format_instructions}\n",
    "        question: {query}\n",
    "        document: {doc}\n",
    "        relevance_score:\"\"\",\n",
    "        input_variables=[\"query\", \"doc\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=3000)\n",
    "    chain = human_message_prompt | llm | parser\n",
    "    scored_docs = []\n",
    "    for doc in docs:\n",
    "        input_data = {\"query\": query, \"doc\": doc.page_content}\n",
    "        try:\n",
    "            score = chain.invoke(input_data)['relevance_score']\n",
    "            score = float(score)\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {str(e)}\")\n",
    "            default_score = 5  # 기본 점수를 5점으로 설정\n",
    "            print(f\"기본 점수 {default_score}점을 사용합니다.\")\n",
    "            score = default_score\n",
    "        scored_docs.append((doc, score))\n",
    "\n",
    "    reranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, _ in reranked_docs[:top_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UVD4UkDUY_-n",
   "metadata": {
    "id": "UVD4UkDUY_-n"
   },
   "outputs": [],
   "source": [
    "query = \"이 회사의 2022년 영업손실이 정확히 얼마야?\"\n",
    "initial_docs = vectordb.similarity_search(query, k=4)\n",
    "reranked_docs = reranking_documents(query, initial_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GtjlHUxKIOm4",
   "metadata": {
    "id": "GtjlHUxKIOm4"
   },
   "outputs": [],
   "source": [
    "# print first 4 initial documents\n",
    "print(f\"Query: {query}\\n\\n\")\n",
    "\n",
    "print(\"Top initial documents:\")\n",
    "for i, doc in enumerate(initial_docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\\nTop reranked documents:\")\n",
    "for i, doc in enumerate(reranked_docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content)  # Print first 200 characters of each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UyZZXECAZGsD",
   "metadata": {
    "id": "UyZZXECAZGsD"
   },
   "outputs": [],
   "source": [
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cWhNHeVKZLjF",
   "metadata": {
    "id": "cWhNHeVKZLjF"
   },
   "outputs": [],
   "source": [
    "# 커스텀 리트리버 체인을 생성합니다.\n",
    "class CustomRetriever(BaseRetriever):\n",
    "\n",
    "    vectorstore: Any = Field(description=\"Retrival을 위한 벡터스토어\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    # num_docs 파라미터로 리랭킹 후 반환할 최종 문서의 수를 정의합니다.\n",
    "    def get_relevant_documents(self, query: str, num_docs=2) -> List[Document]:\n",
    "        initial_docs = self.vectorstore.similarity_search(query, k=4)\n",
    "        return reranking_documents(query, initial_docs, top_n=num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98hxT2RvZQKZ",
   "metadata": {
    "id": "98hxT2RvZQKZ"
   },
   "outputs": [],
   "source": [
    "# custom retriever 인스턴스를 생성합니다.\n",
    "custom_retriever = CustomRetriever(vectorstore=vectordb)\n",
    "\n",
    "# 답변용 LLM 인스턴스를 생성합니다.\n",
    "llm = ChatOpenAI(temperature=0.2, model_name=\"gpt-4o\")\n",
    "\n",
    "# RetrievalQA 체인을 생성합니다.\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=custom_retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lz_suTj0Qyjh",
   "metadata": {
    "id": "lz_suTj0Qyjh"
   },
   "outputs": [],
   "source": [
    "qa_chain.invoke(\"이 회사의 2022년 영업손실이 정확히 얼마야?\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
