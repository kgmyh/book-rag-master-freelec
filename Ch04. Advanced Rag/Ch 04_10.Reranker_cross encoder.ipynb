{"cells":[{"cell_type":"code","source":["!pip install langchain langchain_openai langchain_community pypdf faiss-cpu"],"metadata":{"id":"cJy1t37GsyL9"},"id":"cJy1t37GsyL9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","#OpenAI에서 발급받은 API Key를 'sk-...' 부분에 기입합니다.\n","os.environ[\"OPENAI_API_KEY\"] = 'sk-...'"],"metadata":{"id":"U3aOf1kttmdQ"},"id":"U3aOf1kttmdQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_community.document_loaders import PyPDFLoader\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","\n","file_path = (\n","    \"/content/투자설명서.pdf\"\n",")\n","loader = PyPDFLoader(file_path)\n","\n","doc_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap = 100)\n","\n","docs = loader.load_and_split(doc_splitter)"],"metadata":{"id":"u9eVNXBIUTsb"},"id":"u9eVNXBIUTsb","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_openai.embeddings import OpenAIEmbeddings\n","\n","# 데이터를 임베딩으로 변환\n","embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")"],"metadata":{"id":"wtwTgjcwQp1o"},"id":"wtwTgjcwQp1o","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FAISS 라이브러리 임포트\n","from langchain_community.vectorstores import FAISS\n","\n","# FAISS 벡터스토어 생성\n","faiss_store = FAISS.from_documents(docs, embedding)\n","# FAISS 벡터스토어 저장\n","persist_directory = \"/content/DB\"\n","faiss_store.save_local(persist_directory)"],"metadata":{"id":"p3PNlgs44qHB"},"id":"p3PNlgs44qHB","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 저장한 FAISS DB 불러오기\n","vectordb = FAISS.load_local(persist_directory, embeddings=embedding, allow_dangerous_deserialization=True)"],"metadata":{"id":"urRxIxM3sUcS"},"id":"urRxIxM3sUcS","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain.docstore.document import Document\n","from typing import List, Dict, Any, Tuple\n","from langchain.chat_models import ChatOpenAI\n","from sentence_transformers import CrossEncoder\n","from langchain_core.retrievers import BaseRetriever\n","from langchain.chains import RetrievalQA"],"metadata":{"id":"QO7i-mOHQ4vx"},"id":"QO7i-mOHQ4vx","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ms-marco-MiniLM-L-12-v2 모델 다운로드\n","crossencoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')"],"metadata":{"id":"NkIsOHAOQ7AY"},"id":"NkIsOHAOQ7AY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Retriever_with_cross_encoder(BaseRetriever):\n","    vectorstore: Any = Field(description=\"초기 검색을 위한 벡터 저장소\")\n","    crossencoder: Any = Field(description=\"재순위화를 위한 크로스 인코더 모델\")\n","    k: int = Field(default=5, description=\"초기에 검색할 문서 수\")\n","    rerank_top_k: int = Field(default=2, description=\"재순위화 후 최종적으로 반환할 문서 수\")\n","\n","    class Config:\n","        arbitrary_types_allowed = True\n","\n","    def get_relevant_documents(self, query: str) -> List[Document]:\n","        # 초기 검색\n","        initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n","\n","        # 하이브리드 인코더용 쌍 준비\n","        pairs = [[query, doc.page_content] for doc in initial_docs]\n","\n","        # 하이브리드 인코더 점수 획득\n","        scores = self.crossencoder.predict(pairs)\n","\n","        # 점수별 문서 정렬\n","        scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n","\n","        # 상위 재순위화 문서 반환\n","        return [doc for doc, _ in scored_docs[:self.rerank_top_k]]"],"metadata":{"id":"sLBgdtjK6UUX"},"id":"sLBgdtjK6UUX","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 크로스인코더 기반 리트리버 인스턴스 생성\n","cross_encoder_retriever = Retriever_with_cross_encoder(\n","    vectorstore=vectordb,\n","    crossencoder=crossencoder,\n","    k=4,  # 초기 밀집검색으로 반환할 문서 수를 설정\n","    rerank_top_k=2  # 리랭킹을 통해 최종적으로 반환할 문서 수를 설정\n",")\n","\n","# 답변용 LLM 인스턴스 생성\n","llm = ChatOpenAI(temperature=0.2, model_name=\"gpt-4o\")"],"metadata":{"id":"GQgtEgOLRtwJ"},"id":"GQgtEgOLRtwJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# RetrievalQA 체인 인스턴스 생성\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm=llm,\n","    chain_type=\"stuff\",\n","    retriever=cross_encoder_retriever,\n","    return_source_documents=True\n",")"],"metadata":{"id":"XRsXe5Q47eft"},"id":"XRsXe5Q47eft","execution_count":null,"outputs":[]},{"cell_type":"code","source":["query = \"이 회사의 2022년 영업손실이 정확히 얼마야?\"\n","result = qa_chain({\"query\": query})\n","\n","print(f\"\\n질문: {query}\")\n","print(f\"답변: {result['result']}\")\n","print(\"\\n답변 근거 문서:\")\n","for i, doc in enumerate(result[\"source_documents\"]):\n","    print(f\"\\nDocument {i+1}:\")\n","    print(doc.page_content)  # Print each document"],"metadata":{"id":"GtjlHUxKIOm4"},"id":"GtjlHUxKIOm4","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}